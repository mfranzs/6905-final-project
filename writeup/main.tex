\documentclass[letterpaper]{article}
\usepackage[utf8]{inputenc}
\usepackage[margin=1.25in]{geometry}
\usepackage{parskip, tikz, amsmath, hyperref, listings, pgffor, courier, color, graphicx}
\usetikzlibrary{arrows.meta, arrows}

\definecolor{mygreen}{rgb}{0,0.6,0}
\definecolor{mygray}{rgb}{0.5,0.5,0.5}
\definecolor{mymauve}{rgb}{0.58,0,0.82}

\lstset{
  basicstyle=\small\ttfamily,
  commentstyle=\color{mygreen},
  keywordstyle=\color{blue},
  stringstyle=\color{mymauve}
}

\title{Automating Data Structure Transformations Through Type Chaining}

\author{
  Martin Schneider\\
  \texttt{martinfs@mit.edu} \and
  Josh Gruenstein\\
  \texttt{jgru@mit.edu}
}

\date{6.905 Spring 2019}
 
\begin{document}
 
\maketitle

\begin{abstract}
We propose a system for automating multi-step type transformations in MIT Scheme.  After registering a set of predicates and transformations between them, the programmer can request data be transformed into a given predicate, or set of predicates.  The system then performs a backtracking search to find an appropriate type conversion flow, and can either perform the conversion or return generated conversion code.  This eliminates much of the boilerplate and mental overhead involved in many software systems dealing with data of different types.
\end{abstract}

\section{Introduction}

Much of programming involves manipulation and transformation of data into different types.  Internet connected systems serialize HTTP data into some format, then translate to a JSON type and finally to a normal data structure.  An image processing system may convert images from a filename to a JPEG type to a RGB type to a gray-scale image.  A command line program might parse a command line input, to a split list, to a data-structure with \texttt{int}s and \texttt{string}s and \texttt{flag}s, and finally to commands to be executed.

\begin{figure}[h!]
\centering

\resizebox{14cm}{!} {
  \input{figures/webserver.tex}
}

\caption{A type conversion diagram for a webserver.}
\label{webserver}
\end{figure}

Languages with type annotations or inference often have the information necessary to infer these flows, but instead force the programmer to explicitly notate the conversion process.  This leads to more code and more thinking, which we believe to be universally worse than less code and less thinking.

To remedy this, we propose a system capable of automatically generating these conversion flows.  To achieve this, we built the following functionality in MIT Scheme, which we'll elaborate on in later sections:

\begin{enumerate}
  \item A method of registering predicates: functions that match a certain type.
  \item A method of registering sub-types of predicates.
  \item Support for ``compound predicates,'' groups of element-wise predicates that match lists.
  \item A method of registering conversions between predicates, building up a ``predicate conversion graph'' where nodes represent predicates, and edges represent transformations on predicates and an accompanying transformation on data that matches the start predicate.
  \item A search engine that, given an input predicate, explores the predicate conversion graph to find paths to a given output predicate.
  \item A programmer-facing API for explicitly converting data, exploring conversion paths, and generating type conversion code.
\end{enumerate}

We'll demonstrate how this system provides an extremely flexible basis for automatic type conversion using multiple examples.

\section{Type System}

Trivially, any system capable of finding type transformations must have a type system, where the inputs and outputs of functions are labeled with a given type.  We chose to use predicates to represent our types: functions that return true if the input matches the type.  This provides us with a simple and flexible type system.  We then provide functionality to \textit{register} predicates by adding them as nodes to our predicate conversion graph, such that they can be used by the system.

\begin{figure}[h!]
\centering
\input{figures/type_graph.tex}
\caption{An example predicate conversion graph.}
\label{graph}
\end{figure}

In this graph, edges represent transformations between predicates.  However, unlike what the figure above may suggest, our system's type conversion graph is dynamic; rather than storing edges as having a source and a sink, edges have a source and a predicate transformation function, which given the source returns a sink.  This allows fancy inferred conversions using dynamic types, such doubling lists of arbitrary lengths.

In addition to the predicate transformation graph, we also store a graph of predicate subtypes and super-types.  We chose to use a separate data structure for this (rather than just creating identity transformations in the predicate conversion graph) in order to allow using super-type transformations without losing information from the original predicate.  For example, in the list doubling example, imagine a \texttt{list-len-2?} predicate were transformed into a \texttt{list?} predicate such that it could be doubled.  Doing so would lose the information that the list is of length two, forcing the search to occur on the actual data rather than just on the predicates.  This would be far more computationally intensive and could lead to negative side effects from actually executing transformations during the search without the programmer's permission. 

\section{Search Engine}

Given the previously defined predicate conversion graph, conversion paths between simple predicates such as \texttt{string?}, \texttt{number?}, and even \texttt{list-len-2?} can be found with a basic backtracking search.  Introducing subtypes only slightly increases complexity by forcing the search to consider edges not only from the source node, but also from any supertype nodes.

However, if we want to allow even more complex type chaining, we should be able to operate not just on predicates, but on groups of predicates, or ``compound predicates''.  For example, if we define a transformation from \texttt{(number? number?)} to \texttt{point?}, our search engine should be able to convert \texttt{(string?, string?)} to \texttt{point?} (by first separately converting each string to a number).  We call these operations on compound predicates \textit{compound transformations}.

Finally, in addition to being able to manipulate and transform compound predicates, we should also be able to branch transformations to form them.  Using our \texttt{point?} example again, if we've defined \texttt{point:x} and \texttt{point:y} as transformations from \texttt{point?} to \texttt{number?}, we should be able to infer a path from \texttt{point?} to \texttt{(number? number?)}.  We call these operations of branching into compound predicates \textit{joiner transformations}.

Our search engine supports both compound, joiner, and normal transformations.

\subsection{Handling of compound transformations}

Our standard search process works by querying the predicate transformation graph to find all possible transformations, filtering out predicates already visited in the current type flow, then recursing to try each transformation.  We extend this to compound transformations by considering each possible transformation of each predicate (or none), and taking the crossproduct of the predicate transformations to get each possible transformation for the compound predicate.

\begin{figure}[h!]
\centering
\input{figures/crossproduct.tex}
\caption{Transformations of \texttt{(string? number?)} using the Figure \ref{graph} graph.}
\label{crossproduct}
\end{figure}

We can now filter out already visited transformations, and recurse on the remaining transformations to explore paths they may be a part of.

\subsection{Handling of joiner transformations}

As discussed above, we'd like to be able to branch predicates into compound predicates.  One motivating example for this is the \texttt{person?} record type, with attributes \texttt{person:first} and \texttt{person:last}, each with corresponding predicates.  We'd like to be able to automatically convert a \texttt{person?} into a \texttt{(person:first? person:last?)} (and then automatically create a \texttt{full-name?} from the \texttt{(person:first? person:last?)}). To do so, we would need two paths of execution, one generating the \texttt{(person:first?)} and the other the \texttt{(person:last?)}, and then a joiner that combines the output of these execution paths into a compound predicate.

Here's how we handle these joiner transformations:
\begin{enumerate}
  \item Find all possible compound predicate targets or sub-targets by looking at the conversion target and at all compound predicates registered in the predicate conversion graph.
  \item As we search, store all the predicates we've been able to create and the paths that we took to get there.
  \item After every time we arrive at a new predicate, check if we can now create a new type of compound predicate. If so, create a joiner that transform that stores the sub-paths for creating each of the sub-prediactes in the compound-predicate, and start a new search from this intermediate compound predicate to the target predicate.
\end{enumerate}

This method is less efficient than, for example, working backwards from the target predicate.  However, it is an extensible modification to the original search process, and is likely asymptotically equivalent.

\section{Path Visualization and Code Generation}
Our search engine ouputs a list of structures that transform the input predicate into the desired output predicate. In most cases, this structure is a simple path where each transform function can be applied to the output of the previous transform. For example, requesting a transformation from \texttt{number?} to \texttt{symbol?} is a list of transforms \texttt{'(number->string string->symbol)}. (This example is simplified. Note that our actual path data structure stores full transform datastructures that include the desired input-predicate and the predicate-transform function in addition to the data-transform function).

In cases with joiner transforms, our generated datastructure is a tree of paths. Each leaf of our tree is a transform that separately takes in the full input. Nodes with multiple inputs are joiner transforms that take the output of each path and combine it into a compound predicate.

Code generation proceeds by simply traversing over this datastructure to build up a LISP expression. Our engine knows the right type of code to generate for each type of transform. Normal transforms use simple function application. Compound transforms generate a map that separately applies each transform function to the input list (see the "compound transform" example below). Joiner transforms separately compute each sub-path and passing them into the transform function as a list of arguments.

\section{API Reference}

Programmers can interact with our system through the following method calls.  More complete examples can be found in our codebase, linked to in Appendix A.

\newcommand{\doc}[3]{\item \texttt{#1}: #2\\\\Example: \texttt{#3}}

\begin{list}{$>$}{}
  \doc{(register-predicate! predicate)}
  {Registers a given predicate by adding it to the predicate conversion graph.}
  {(register-predicate! number?)}

  \doc{(register-super! subpredicate superpredicate)}
  {Registers a predicate as a subpredicate of another predicate.}
  {\\(define (is-three? num) (eq? num 3))\\
  (register-super! is-three? number?)}
  
  \doc{(register-type-transform! input-type output-type transformation-function)}{Registers a function as a transformation between two registered predicates.}{(register-type-transform! number? string? number->string)}

  \doc{(register-type-transform-f! input-type predicate-transform-function \\transformation-function)}{Registers a function as a transformation from the input predicate, into a new predicate generated by a predicate transform function.  See \\\texttt{example-list-types.scm} for an example of where this could be useful.}{\\(register-type-transform! number? (lambda (x) string?) number->string)}

  \doc{(get-transformations input-predicate output-predicate)}{Returns a list of transformations from the input predicate to the output predicate.}{(get-transformations string? number?)}

  \doc{(create-compound-transformation transformation-path)}{Given a transformation path from \texttt{get-transformations}, return a method that transforms according to that path.}{\\((create-compound-transformation (car\\
  (get-transformations number? string?))) 5)}

  \doc{(transform-with-first-path input-predicate output-predicate input-value)}{Find the first path between the input and output predicates, and transform the input accordingly.}{(transform-with-first-path number? string? 5)}

  \doc{(transform-with-first-path input-predicate output-predicate input-value)}{Find the first path between the input and output predicates, and transform the input accordingly.}{(transform-with-first-path number? string? 5)}

  \doc{(debug-transform input-predicate output-predicate input-value)}{Return a list of all possible transformations of input-value, while printing to the console the transformation paths, intermediate values, and autogenerated code.}{(debug-transform number? string? 5)}

  \doc{(debug-transform-to input-value output-predicate)}{Infer the input type, and return all possible transformations to the output-predicate while printing path information to the console.}{(debug-transform-to 5 string?)}
\end{list}

\section{Examples}

Our attached code provides examples of our system in action. We highlight some examples here.

\subsection{Compound Predicates}

As a simple but illustrative example of compound predicates, imagine trying to convert (number?, string?) to (number?, number?). We presumably already have the following type conversion defined at a system level:

\begin{verbatim}
(register-type-transform! string? number? string->number)
\end{verbatim}

Then, running the search automatically generates code for us:
\begin{verbatim}
(debug-transform (list number? string?) (list number? number?) (list 1 "2"))

;;(define (call f in) (f in))
;;(define (identity x) x)
;;(define (n:number?n:string?-to-n:number?n:number? input)
;;  (map 
;;    call 
;;    (list number->string identity) 
;;    input))
\end{verbatim}

\subsection{Record Types}
We explore an example where we have a "database" of records of people. We represent this in scheme with a record type for Person, and auxiliary record types for FullName and FormalTitleName (i.e. Professor Sussman).

\begin{verbatim}
(define (first-name? x) (printable-string? x))
(define (last-name? x) (printable-string? x))
(define (formal-title? x) (printable-string? x))
(define (person:age? x) (number? x))

(define-record-type Person
  (make-person first-name last-name age)
  person?
  (first-name person:first-name) ; first-name?
  (last-name person:last-name) ; last-name?
  (age person:age)) ; person:age?

(define-record-type FullName
  (make-full-name first-name last-name)
  full-name?
  (first-name full-name:first-name) ; first-name?
  (last-name full-name:last-name)) ; last-name?

(define-record-type FormalTitleName
  (make-formal-title-name formal-title last-name)
  formal-title-name?
  (formal-title formal-title-name:formal-title) ; formal-title?
  (last-name formal-title-name:last-name)) ; last-name?

;; ... boilerplate registering predicates for each of the above record types ...
;; (In a production-ready version of our systems, we would have a macro that automatically
;; registers these predicates for record types without requiring any effort from the user
;; other than specifying predicate names for each field as we did in comments above.)

(register-type-transform! full-name? formal-title-name? 
  (lambda (fn)
    (make-formal-title-name 
      (if (is-female-first-name? (full-name:first-name fn)) "Mrs." "Mr.")
      (full-name:last-name fn))))

(register-type-transform! 
  formal-title-name?
  printable-string? 
  (lambda (ftn) 
    (string-append 
     (formal-title-name:formal-title ftn) 
     " "
     (formal-title-name:last-name ftn))) )
\end{verbatim}

Now that we've defined our record types, we can automatically begin to search for transformations between them. For example, we can request a transformation from person? to full-name?.

\begin{verbatim}
(define gs (make-person "Gerald" "Sussman" 18))
(debug-transform person? full-name? gs)
;; One path gets returned, and the following code snippet is automatically generated.
;; Note that this transformation involves automatically identifying that the first-name? 
;; and last-name? can be separately read out of the input and composed into 
;; (first-name?, last-name?) which can then be transformed into a full-name?
;; (define (person?-to-full-name? input)
;;  (make-full-name (person:first-name input) (person:last-name input)))
\end{verbatim}

For a more complicated example, we can automatically search for ways to print out a person:

\begin{verbatim}
(define gs (make-person "Gerald" "Sussman" 18))
(debug-transform person? full-name? gs)
;; Multiple possible transformations are found, resulting in the following values:
;; "Gerald Sussman", "Mr. Sussman", "Sussman", and "Gerald".
;; For example, the following code-snippet is generated to create "Mr. Sussman": 
;;(define (person?-to-printable-string? input)
;;  (print-formal-title-name 
;;      (make-formal-title-name 
;;        (first-name-to-formal-title (person:first-name input)) 
;;        (person:last-name input))))

\end{verbatim}

Note that generating this example required a few steps of translation:
\begin{enumerate}
  \item Generate first-name? from person.
  \item Generate last-name? from person.
  \item Generate formal-title? from first-name?
  \item Use a joiner transform to generate a compound predicate (formal-title?, last-name?) by combing the paths to formal-title? and last-name?
  \item Generate formal-title-name? by passing in the (formal-title?, last-name?) compound predicate as a list of arguments to the formal-title-name constructor
  \item Generate a printable-string? from the formal-title-name?
\end{enumerate}

\subsection{Dynamically Generated Predicates}

Imagine that we want to add a transform that takes a list of a given length and outputs a list of twice the length by duplicating every item. We then want to be able to request generated code that takes a list of length two and returns a list of length 8. For our transform to be fully general, we need to be able to create list predicates that specify the length of our list. Then, we need to be able to compute the output type of our transform from the input type. 

To support this functionality, our search engine allows the output-type of a transform to be computed from the input type. We then implement the above example as follows. Note how we dynamically generate a new list predicate from the input list predicate.

\begin{verbatim}
(define (duplicate-items-in-list lst)
  (apply append (list lst lst)))
  
(register-type-transform-f!
  length-list?
  (lambda (input_type) 
	  (generate-list-predicate
      (* 2 (get-list-predicate-length input_type))))
	duplicate-items-in-list)
\end{verbatim}

To support this functionality, the programmer had to define some a generator for predicates of lists that specify their length:

\begin{verbatim}
;; a length-list is just a list whose type describes its length
(define (length-list? x) (list? x))

(register-predicate! length-list?)
(register-super! length-list? list?)

;; generate a new length-list? predicate with a specific length

(define generate-list-predicate
  (memoize
    (lambda (length)
      (define (list-predicate-with-length? item)
        (and 
          (length-list? item)
          (= length item)))

      (register-list-predicate-length! list-predicate-with-length? length)
      (register-super! list-predicate-with-length? length-list?)
      
      list-predicate-with-length?)))

;; hash table for storing lengths associated with length-list? predicates
(define list-predicate-lengths (make-strong-eq-hash-table)) 

(define (register-list-predicate-length! list-predicate-with-length? length)
  (hash-table-set! list-predicate-lengths list-predicate-with-length? length))

(define (get-list-predicate-length list-predicate-with-length?)
  (hash-table/get list-predicate-lengths list-predicate-with-length? -1))
\end{verbatim}

We can now request a transformation from a list of length 2 2 to a list of length 8. Note that the search engine realizes it can apply the this transformation to list-len-2? because each generated predicate is marked as a subtype of list-len?. Also note that search engine performs this transformation in a manner that doesn't lose information about the list's length (for example, we could not first convert list-len-2? to length-list? because we would lose the knowledge that len=2).

\begin{verbatim}

(define list-len-2? (generate-list-predicate 2))
(define list-len-8? (generate-list-predicate 8))

(debug-transform
  list-len-2?
  list-len-8?
  (list 2 3))

;; "Found 1 paths: "
;; "------"
;; "Code Gen:"
;; (define (list-predicate-with-length?-to-list-predicate-with-length? input)
;;   (duplicate-items-in-list (duplicate-items-in-list input)))
;; "Output value:"
;; (2 3 2 3 2 3 2 3)

\end{verbatim}

\section{Discussion}

A common goal of programming languages is to minimize the amount of code that needs to be written.  The programmer should be able to specify what they want as tersely as possible, and the computer should do the rest.  We propose one such mechanism for allowing computers and languages to infer large components of programs, by focusing on types and conversion flows between them.  Changing one's perspective to view more of computation as type conversion provides a framework from which more of the program can be easily inferred by a smart compiler.

Another interesting aspect of this project is the collaborative nature between our system and the programmer.  By being less verbose in our programming, we force the system to ask us clarifying questions; in this case, which type flow to pick.  We think this is a necessary trade-off for more advanced programming environments, and possibly a useful direction for future research.

We'd also like to note that many of the ideas in this paper are not wholly original.  Our type inference is similar to Prolog's logic-based programming.  Scala has ``implicit conversions,'' which allows the definition of automatic conversions between types (but not chaining without significant extra work).

\appendix
\section{Github Repo Link}

All of our code (including the \LaTeX\, source for this writeup) can be found at the following link:

\begin{center}
  \url{https://github.com/mfranzs/6905-final-project}
\end{center}

We also provide a hard copy in the following pages.

\section{Source Code}

\newcommand*{\sourcefiles}{
    main,
    helpers,
    memoize,
    example-basic,
    example-compound-types,
    example-list-types,
    example-record-types%
}

\foreach \c in \sourcefiles {
  \subsection{\c.scm}
  \lstinputlisting[language=lisp]{../\c.scm}
}


\end{document}
